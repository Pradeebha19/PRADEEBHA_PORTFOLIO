<!DOCTYPE HTML>

<html>
	<head>
		<title>PRADEEBHA</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
				<!-- Note: The "styleN" class below should match that of the banner element. -->
					<header id="header" class="alt style2">
						<a href="index.html" class="logo"><strong>PRADEEBHA</strong> <span>MURUGAVEL</span></a>
						<nav>
							<a href="#menu">Menu</a>
						</nav>
					</header>

				<!-- Menu -->
					<nav id="menu">
						<ul class="links">
							<li><a href="index.html">Home</a></li>
							<li><a href="skills.html">Skill</a></li>
							<li><a href="projects.html">project</a></li>
							<li><a href="experience.html">Experience</a></li>
						</ul>
						<ul class="actions stacked">
							<li><a href="#" class="button primary fit">Get Started</a></li>
							<li><a href="#" class="button fit">Log In</a></li>
						</ul>
					</nav>

				
				<!-- Main -->
					<div id="main">

						<!-- One -->
							

						<!-- Two -->
							<section id="two" class="spotlights">
								<section>
									<a href="spam.html" class="image">
										<img src="images/product.jpg" alt="" data-position="center center" />
									</a>
									<div class="content">
										<div class="inner">
											<header class="major">
												<h3>Product Matching in Data Science</h3>
											</header>
											<p>Product matching deals with identifying product offers deriving from different websites that refer to the same real-world product. In this task, product matching is handled as a binary classification problem: given two product offers decide if they describe the same product (matching) or notÂ (non-matching).</p>
											<ul class="actions">
												
											</ul>
										</div>
									</div>
								</section>
								
							</section>
 <!-- One -->
 <section id="one">
	<div class="inner">
		<header class="major">
			
		</header>

		<!-- Content -->
			<h2 id="content"> ðŸ“ŒIntroduction:</h2>
			<p>In this project, I evaluated several machine learning models for the task of product matching. The goal was to predict whether two products (from a given dataset) are a match or not. This is a binary classification problem, and I used five different models to evaluate and compare their performance on validation and verification datasets.

			<br>
			<li>Models Evaluated

			</li>
			<li>Random Forest

			 </li>
			<li>Logistic Regression</li>
		</li>
		<li>Decision Tree Classifier</li>
		<li>k-Nearest Neighbors (k-NN)
		</li>
		<br>
		<h2 id="content"> Model Evaluation Process:</h2>
			<p>After training each model on the training data, I evaluated their performance on two separate sets:</p>
			<h2 id="content">Validation Set:</h2>
			<p>his dataset was used to validate the models during the training process. It helps in understanding how well the model learned the patterns.
			</p>
			<h2 id="content">Verification (Test) Set:</h2>
			<p> This dataset was used for final evaluation. The model had not seen this data during training, so it provided an indication of the modelâ€™s ability to generalize to new, unseen data.

			</p>
			<h2 id="content">Evaluation Metrics:</h2>
			<p>  used several key metrics to assess model performance:</p>
			<h2 id="content">Accuracy:</h2>
			<p> Measures the proportion of correct predictions. It is a general indicator of model performance but can be misleading with imbalanced datasets.
			</p>
			<h2 id="content">Precision:</h2>
			<p> Indicates how many of the predicted positive cases were actually positive. It is important when false positives are costly.
			</p>
			<h2 id="content">Recall:</h2>
			<p>Measures how many of the actual positive cases were correctly identified by the model. This is critical when false negatives are costly.
			</p>
			<h2 id="content">F1-Score: </h2>
			<p>The harmonic mean of precision and recall. It is especially useful when dealing with imbalanced classes, balancing false positives and false negatives.

			</p>
			<h2 id="content">Confusion Matrix:</h2>
			<p> Provides a more detailed breakdown of predictions by comparing the true labels to the predicted labels. It shows the true positives, false positives, true negatives, and false negatives.
			</p>
			<h2 id="content">Detailed Model Performance:
			</h2>
			<p>Below are the results for each model based on the evaluation metrics:
			</p>
			<h2 id="content">1. Random Forest:</h2>
			<p>Validation Accuracy: 92%</p>
			<p>Verification Accuracy: 73%
			</p>
			<p>Random Forest performed well on the validation set, demonstrating its strong generalization capabilities. However, there was a noticeable drop in performance on the verification set, particularly in recall for the minority class.
			</p>

			<h2 id="content">2. Logistic Regression:
			</h2>
			<p>Validation Accuracy: 89%
			</p>
			<p>Verification Accuracy: 68%

			</p>
			<p>Logistic Regression provided a good performance on the validation set but showed significant weaknesses in recall and precision for the minority class on the verification set. This indicates that the model had difficulties generalizing to unseen data, especially with the minority class.

			</p>

			<h2 id="content">3. Extra Trees Classifier:

			</h2>
			<p>Validation Accuracy: 92%

			</p>
			<p>Verification Accuracy: 75%


			</p>
			<p>The Extra Trees Classifier performed excellently in both validation and verification sets. It exhibited a solid balance between precision and recall and generalized well to unseen data. It was the most consistent performer among all models.
			</p>

			<h2 id="content">4. Decision Treew:</h2>
			<p>Validation Accuracy: 88%</p>
			<p>Verification Accuracy: 72%<p>
			<p>The Decision Tree showed decent performance during training but struggled to maintain the same level of accuracy on the verification set. Its performance was prone to overfitting, as reflected in the higher validation accuracy compared to verification.

			</p>
			<h2 id="content">5. k-Nearest Neighbors (k-NN):</h2>
            <p>Validation Accuracy: 80%<p>
            <p>Verification Accuracy: 70%<p>
            <p>k-NN performed poorly compared to the other models, particularly in recall for the minority class. This suggests that it struggled with distinguishing between positive and negative cases effectively, possibly due to the high dimensionality of the dataset. </p>

			<h2 id="content">Model Comparison Insights:</h2>
				<p>Best Performing Models: Extra Trees Classifier and Random Forest showed the best validation and verification accuracy overall. These models handle complex decision boundaries and can generalize well across different types of data.
			  </p>
			  
			  <h2 id="content">
			  Challenges with Imbalanced Classes:</h2>
				<p>All models showed varying degrees of difficulty with detecting the minority class (class 1). This is common in imbalanced classification problems and suggests that techniques like oversampling, undersampling, or adjusting class weights may be beneficial.</p>
			  <h2 id="content">Overfitting: </h2>
				<p>Models like the Decision Tree showed signs of overfitting, where the model performed significantly better on the training/validation set than on the verification set. This highlights the importance of tuning and cross-validation to prevent overfitting.</p>
			  <h2 id="content">Model Weaknesses:</h2>
				<p>The k-NN model showed the weakest performance, especially on the minority class. This indicates that k-NN may not be the most suitable choice for this problem without further tuning and preprocessing.</p>
			  <h2 id="content">Final Thoughts & Next Steps</h2>
				<p>While the Extra Trees Classifier and Random Forest emerged as the top performers, there is still room for improvement. A few next steps could include:</p>
			  <h2 id="content">Hyperparameter Tuning:</h2>
				<p>Further tuning of model hyperparameters (e.g., tree depth, number of estimators for tree-based models) could enhance model performance.</p>
			  <h2 id="content">Class Imbalance Solutions:</h2>
				<p>Implementing techniques like SMOTE (Synthetic Minority Over-sampling Technique) or adjusting class weights could improve recall for the minority class.</p>
			  <h2 id="content">Ensemble Learning:</h2>
				<p> Combining multiple models (e.g., using stacking or boosting) could leverage the strengths of each individual model and potentially improve overall performance.</p>
			  <h2 id="content">Visualizations and Analysis</h2>h2>
				<p>The model performance was further visualized using various plots, including:</p>
			  <h2 id="content">Bar Plots:</h2>h2>
				<p>Comparing the accuracy of different models.</p>
			  <h2 id="content">Confusion Matrices:</h2>
				<p>Highlighting where each model performed well or failed.</p>
			  <h2 id="content">Pie Charts:</h2>
				<p>Showing the distribution of correctly vs. incorrectly classified products for each model.</p>
			  <h2 id="content">Conclusion</h2>
				<p>This model evaluation provided valuable insights into how different algorithms perform in the context of product matching. While Extra Trees Classifier showed the best overall performance, future work will focus on refining the models further, improving performance on the minority class, and exploring other ensemble learning strategies.</p>
			  
			  
			  

				
			
					</div>

				

					<!-- Footer -->
					<footer id="footer">
						<div class="inner">
							
							<ul class="copyright">
								<li>&copy; Copyright Â© 2025 Pradeebha Murgavel</li><li>All Rights Reserved</li>
								
							</ul>
						</div>
					</footer>

			</div>


		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>